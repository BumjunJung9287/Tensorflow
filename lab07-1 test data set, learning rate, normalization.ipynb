{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2.4362109 [[ 0.06107718 -0.15862946 -1.6793253 ]\n",
      " [-0.84010285 -1.6594412  -0.5215618 ]\n",
      " [-0.73910797  0.6800976  -0.2817133 ]]\n",
      "400 0.6430323 [[-1.7704797  -0.18925242  0.18285593]\n",
      " [-0.874585   -1.0735958  -1.0729239 ]\n",
      " [ 0.17046432  0.17710106 -0.6882891 ]]\n",
      "800 0.5211192 [[-2.5682573  -0.08277263  0.8741509 ]\n",
      " [-0.8492161  -1.0253568  -1.1465331 ]\n",
      " [ 0.45433146  0.11969226 -0.9147473 ]]\n",
      "1200 0.45508632 [[-3.170425    0.03390167  1.3596404 ]\n",
      " [-0.8513607  -1.0035015  -1.1662431 ]\n",
      " [ 0.68508846  0.07407075 -1.0998832 ]]\n",
      "1600 0.40943423 [[-3.673743    0.13806997  1.7587898 ]\n",
      " [-0.8551784  -0.99023676 -1.1756897 ]\n",
      " [ 0.8786749   0.03702214 -1.2564195 ]]\n",
      "2000 0.3750204 [[-4.1104517   0.22703263  2.1065323 ]\n",
      " [-0.8581047  -0.981239   -1.1817595 ]\n",
      " [ 1.0459824   0.00720357 -1.3939106 ]]\n",
      "[[4.71771928e-05 1.05870888e-02 9.89365697e-01]\n",
      " [7.16943468e-04 5.03622070e-02 9.48920786e-01]\n",
      " [5.03092483e-02 4.42990184e-01 5.06700635e-01]\n",
      " [2.56621778e-01 6.25357330e-01 1.18020914e-01]\n",
      " [3.17905635e-01 6.05561793e-01 7.65325874e-02]\n",
      " [1.74201936e-01 6.14257097e-01 2.11541057e-01]\n",
      " [5.58089972e-01 4.25710946e-01 1.61990821e-02]\n",
      " [8.06057870e-01 1.92465514e-01 1.47663511e-03]]\n",
      "Prediction:  [2 2 2]\n",
      "Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "x_data = [[1,2,1],[1,3,2],[1,3,4],[1,5,5],[1,7,5],[1,2,5],[1,6,6],[1,7,7]]\n",
    "y_data = [[0,0,1],[0,0,1],[0,0,1],[0,1,0],[0,1,0],[0,1,0],[1,0,0],[1,0,0]]\n",
    "\n",
    "#Evaluation our model using test dataset\n",
    "x_test = [[2,1,1],[3,1,2],[3,3,4]]\n",
    "y_test = [[0,0,1],[0,0,1],[0,0,1]]\n",
    "\n",
    "X = tf.placeholder(\"float\",[None,3])\n",
    "Y = tf.placeholder(\"float\",[None,3])\n",
    "W = tf.Variable(tf.random_normal([3,3]),dtype = tf.float32)\n",
    "b = tf.Variable(tf.random_normal([3]))\n",
    "\n",
    "hypothesis = tf.nn.softmax(tf.matmul(X,W)+b)\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y*tf.log(hypothesis),axis = 1))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.05).minimize(cost)\n",
    "\n",
    "#Corrent prediction Test model\n",
    "prediction = tf.argmax(hypothesis,1)\n",
    "is_correct = tf.equal(prediction,tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct,tf.float32))\n",
    "\n",
    "#launch graph\n",
    "with tf.Session() as sess:\n",
    "    #Initialize TensorFlow variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(2001):\n",
    "        cost_val, W_val, _, hy_val = sess.run([cost,W,optimizer,hypothesis],feed_dict = {X:x_data, Y:y_data})\n",
    "        if step%400==0:\n",
    "            print(step,cost_val,W_val)\n",
    "    print(hy_val)\n",
    "    #prediction\n",
    "    print(\"Prediction: \",sess.run(prediction,feed_dict = {X:x_test}))\n",
    "    #Calculate the accuracy\n",
    "    print(\"Accuracy: {:.2%}\".format(sess.run(accuracy,feed_dict = {X:x_test, Y:y_test})))\n",
    "##계속 accuracy가 너무 낮게 나왔던 이유: for문안의 training을 if문 안에 넣어버려서 학습이 몇번 이뤄지지 않게 되어버림      \n",
    "#밖에 놓아서 반복이 가능하게하니 acc 100%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3.388558 [[-3.2859426   1.0989507  -0.22410768]\n",
      " [-3.8908763   2.9255838   1.6960953 ]\n",
      " [-5.199213    2.853474    1.3409916 ]]\n",
      "40 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "80 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "120 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "160 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "200 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "Prediction: [0 0 0]\n",
      "Accuracy: 0.00%\n"
     ]
    }
   ],
   "source": [
    "#learning rate 크게해본 버전\n",
    "# Lab 7 Learning rate and Evaluation\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(777)  # for reproducibility\n",
    "\n",
    "x_data = [[1, 2, 1],\n",
    "          [1, 3, 2],\n",
    "          [1, 3, 4],\n",
    "          [1, 5, 5],\n",
    "          [1, 7, 5],\n",
    "          [1, 2, 5],\n",
    "          [1, 6, 6],\n",
    "          [1, 7, 7]]\n",
    "y_data = [[0, 0, 1],\n",
    "          [0, 0, 1],\n",
    "          [0, 0, 1],\n",
    "          [0, 1, 0],\n",
    "          [0, 1, 0],\n",
    "          [0, 1, 0],\n",
    "          [1, 0, 0],\n",
    "          [1, 0, 0]]\n",
    "\n",
    "# Evaluation our model using this test dataset\n",
    "x_test = [[2, 1, 1],\n",
    "          [3, 1, 2],\n",
    "          [3, 3, 4]]\n",
    "y_test = [[0, 0, 1],\n",
    "          [0, 0, 1],\n",
    "          [0, 0, 1]]\n",
    "\n",
    "X = tf.placeholder(\"float\", [None, 3])\n",
    "Y = tf.placeholder(\"float\", [None, 3])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([3, 3]))\n",
    "b = tf.Variable(tf.random_normal([3]))\n",
    "\n",
    "# tf.nn.softmax computes softmax activations\n",
    "# softmax = exp(logits) / reduce_sum(exp(logits), dim)\n",
    "hypothesis = tf.nn.softmax(tf.matmul(X, W) + b)\n",
    "\n",
    "# Cross entropy cost/loss\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(hypothesis), axis=1))\n",
    "# Try to change learning_rate to small numbers\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=2.1).minimize(cost)\n",
    "\n",
    "# Correct prediction Test model\n",
    "prediction = tf.argmax(hypothesis, 1)\n",
    "is_correct = tf.equal(prediction, tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "\n",
    "# Launch graph\n",
    "with tf.Session() as sess:\n",
    "    # Initialize TensorFlow variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(201):\n",
    "        cost_val, W_val, _ = sess.run([cost, W, optimizer], feed_dict={X: x_data, Y: y_data})\n",
    "        if step%40 == 0:\n",
    "            #cost_val, W_val, _ = sess.run([cost, W, optimizer], feed_dict={X: x_data, Y: y_data})\n",
    "            print(step, cost_val, W_val)\n",
    "\n",
    "    # predict\n",
    "    print(\"Prediction:\", sess.run(prediction, feed_dict={X: x_test}))\n",
    "    # Calculate the accuracy\n",
    "    print(\"Accuracy: {:.2%}\".format(sess.run(accuracy, feed_dict={X: x_test,Y:y_test})))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
