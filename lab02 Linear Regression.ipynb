{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.7360891 [0.4344597] [-0.10296354]\n",
      "50 0.0016968851 [0.95091647] [0.10769349]\n",
      "100 0.0013232321 [0.9577472] [0.09603966]\n",
      "150 0.0010401821 [0.96254146] [0.08515196]\n",
      "200 0.0008176768 [0.9667886] [0.07549726]\n",
      "250 0.00064277 [0.9705542] [0.06693731]\n",
      "300 0.0005052727 [0.9738928] [0.05934777]\n",
      "350 0.00039719432 [0.9768529] [0.05261881]\n",
      "400 0.00031222744 [0.97947747] [0.04665278]\n",
      "450 0.00024544066 [0.9818044] [0.04136307]\n",
      "500 0.0001929381 [0.98386735] [0.03667323]\n",
      "550 0.00015166771 [0.9856965] [0.03251512]\n",
      "600 0.00011922356 [0.9873183] [0.02882851]\n",
      "650 9.372112e-05 [0.9887562] [0.02555989]\n",
      "700 7.367373e-05 [0.990031] [0.02266194]\n",
      "750 5.7914032e-05 [0.9911613] [0.02009243]\n",
      "800 4.5525318e-05 [0.9921635] [0.01781429]\n",
      "850 3.578749e-05 [0.993052] [0.01579447]\n",
      "900 2.8131852e-05 [0.9938398] [0.01400362]\n",
      "950 2.2114755e-05 [0.9945382] [0.01241589]\n",
      "1000 1.738369e-05 [0.99515754] [0.01100816]\n",
      "1050 1.3665194e-05 [0.99570656] [0.00976005]\n",
      "1100 1.07425885e-05 [0.99619335] [0.00865343]\n",
      "1150 8.444351e-06 [0.9966249] [0.0076723]\n",
      "1200 6.638275e-06 [0.9970076] [0.00680242]\n",
      "1250 5.218297e-06 [0.9973468] [0.00603118]\n",
      "1300 4.1022845e-06 [0.99764764] [0.00534736]\n",
      "1350 3.2245407e-06 [0.9979144] [0.00474107]\n",
      "1400 2.534867e-06 [0.9981508] [0.00420354]\n",
      "1450 1.99273e-06 [0.9983605] [0.00372693]\n",
      "1500 1.5663342e-06 [0.99854636] [0.0033044]\n",
      "1550 1.2313682e-06 [0.99871117] [0.00292971]\n",
      "1600 9.678382e-07 [0.9988573] [0.00259757]\n",
      "1650 7.608904e-07 [0.99898684] [0.00230311]\n",
      "1700 5.982233e-07 [0.99910164] [0.00204204]\n",
      "1750 4.702806e-07 [0.99920344] [0.00181057]\n",
      "1800 3.6974942e-07 [0.9992938] [0.00160537]\n",
      "1850 2.9068173e-07 [0.9993738] [0.0014234]\n",
      "1900 2.2848373e-07 [0.9994448] [0.0012621]\n",
      "1950 1.7966282e-07 [0.9995076] [0.00111913]\n",
      "2000 1.4125821e-07 [0.99956346] [0.00099234]\n"
     ]
    }
   ],
   "source": [
    "x_train = [1,2,3]\n",
    "y_train = [1,2,3]\n",
    "\n",
    "#tf.randon_normal(shape), [1] => rank1, D0 = 1\n",
    "W = tf.Variable(tf.random_normal([1]), name = 'weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name = 'bias')\n",
    "\n",
    "#Hypothesis XW + b\n",
    "hypothesis = x_train * W + b\n",
    "\n",
    "#cost(loss) function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - y_train)) \n",
    "#tf.의 메소드 안에 math, random등 이런저런 모듈이 포함되어있는듯\n",
    "#tf.reduce_mean -> iter()을 받아서 평균 return\n",
    "\n",
    "##cost의 Minimization!!! (GradientDescent)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.01)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "#위에서 만들어진 graph의 실행!\n",
    "sess = tf.Session()\n",
    "#글로벌 변수 초기화\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "\n",
    "for step in range(2001):\n",
    "    sess.run(train)\n",
    "    if step%50 == 0:\n",
    "        print(step,sess.run(cost),sess.run(W),sess.run(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1.5\n"
     ]
    }
   ],
   "source": [
    "c = tf.reduce_mean([1,2])\n",
    "print(sess.run(c))\n",
    "b = tf.reduce_mean([1,2.0])\n",
    "print(sess.run(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 32.424175 [-1.6797091] [0.7853301]\n",
      "50 0.30713356 [0.3526732] [1.4566803]\n",
      "100 0.24123782 [0.4309046] [1.2936461]\n",
      "150 0.18963492 [0.4954434] [1.1469758]\n",
      "200 0.1490704 [0.5526511] [1.0169294]\n",
      "250 0.11718282 [0.6033726] [0.90162736]\n",
      "300 0.09211642 [0.6483431] [0.7993989]\n",
      "350 0.07241188 [0.6882147] [0.70876116]\n",
      "400 0.056922335 [0.7235657] [0.6284003]\n",
      "450 0.044746134 [0.75490844] [0.55715084]\n",
      "500 0.035174552 [0.78269744] [0.49397978]\n",
      "550 0.027650386 [0.80733573] [0.43797123]\n",
      "600 0.021735722 [0.82918036] [0.38831314]\n",
      "650 0.017086267 [0.84854823] [0.34428537]\n",
      "700 0.01343136 [0.8657202] [0.3052496]\n",
      "750 0.01055827 [0.8809451] [0.27063975]\n",
      "800 0.00829977 [0.8944438] [0.23995404]\n",
      "850 0.006524391 [0.906412] [0.21274757]\n",
      "900 0.005128765 [0.91702324] [0.18862578]\n",
      "950 0.004031665 [0.92643124] [0.167239]\n",
      "1000 0.0031692598 [0.9347727] [0.14827703]\n",
      "1050 0.0024913242 [0.94216835] [0.13146506]\n",
      "1100 0.001958412 [0.94872534] [0.11655928]\n",
      "1150 0.0015394861 [0.954539] [0.10334357]\n",
      "1200 0.0012101795 [0.95969343] [0.09162626]\n",
      "1250 0.0009513092 [0.9642635] [0.08123747]\n",
      "1300 0.00074781425 [0.9683153] [0.07202662]\n",
      "1350 0.0005878531 [0.97190785] [0.06386002]\n",
      "1400 0.00046210634 [0.97509307] [0.05661941]\n",
      "1450 0.00036325757 [0.977917] [0.05019978]\n",
      "1500 0.00028555075 [0.9804209] [0.04450798]\n",
      "1550 0.00022446892 [0.98264086] [0.03946155]\n",
      "1600 0.00017645374 [0.984609] [0.0349873]\n",
      "1650 0.00013870942 [0.9863541] [0.03102036]\n",
      "1700 0.00010903684 [0.9879013] [0.02750317]\n",
      "1750 8.571442e-05 [0.9892731] [0.02438483]\n",
      "1800 6.737843e-05 [0.9904893] [0.02162003]\n",
      "1850 5.2964664e-05 [0.99156773] [0.01916865]\n",
      "1900 4.163639e-05 [0.9925237] [0.01699526]\n",
      "1950 3.2729728e-05 [0.9933715] [0.01506829]\n",
      "2000 2.572873e-05 [0.99412304] [0.01335981]\n"
     ]
    }
   ],
   "source": [
    "##placeholder을 이용한 위와 동일한 코드!\n",
    "\n",
    "#x_train = [1,2,3]\n",
    "#y_train = [1,2,3]\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "#tf.randon_normal(shape), [1] => rank1, D0 = 1 (변하는 값들, parameter)\n",
    "W = tf.Variable(tf.random_normal([1]), name = 'weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name = 'bias')\n",
    "\n",
    "#Hypothesis XW + b\n",
    "hypothesis = X * W + b\n",
    "\n",
    "#cost(loss) function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y)) \n",
    "#tf.의 메소드 안에 math, random등 이런저런 모듈이 포함되어있는듯\n",
    "#tf.reduce_mean -> iter()을 받아서 평균 return\n",
    "\n",
    "##cost의 Minimize!!! (GradientDescent)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.01)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "#위에서 만들어진 graph의 실행!\n",
    "sess = tf.Session()\n",
    "#글로벌 변수 초기화\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "\n",
    "for step in range(2001):\n",
    "    #sess.run(train, feed_dict = {X: [1,2,3], Y: [1,2,3]})\n",
    "    cost_val, W_val, b_val, _ = \\\n",
    "        sess.run([cost, W, b, train], feed_dict = {X: [1,2,3], Y: [1,2,3]})\n",
    "    if step%50 == 0:\n",
    "        #print(step,sess.run(cost),sess.run(W),sess.run(b))\n",
    "        print(step, cost_val, W_val, b_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.94904613 [0.5602135] [0.94326353]\n",
      "50 0.104927994 [0.7904086] [0.85669035]\n",
      "100 0.07478409 [0.8230576] [0.7388181]\n",
      "150 0.053300034 [0.8506205] [0.6393073]\n",
      "200 0.03798784 [0.87389] [0.5552972]\n",
      "250 0.027074635 [0.8935346] [0.48437393]\n",
      "300 0.019296568 [0.91011906] [0.42449856]\n",
      "350 0.013753025 [0.9241202] [0.37395027]\n",
      "400 0.009802023 [0.9359402] [0.33127606]\n",
      "450 0.006986078 [0.94591904] [0.29524928]\n",
      "500 0.004979108 [0.95434344] [0.26483467]\n",
      "550 0.003548699 [0.9614555] [0.23915774]\n",
      "600 0.002529227 [0.96745974] [0.21748063]\n",
      "650 0.0018026258 [0.97252864] [0.19918025]\n",
      "700 0.0012847668 [0.9768079] [0.18373066]\n",
      "750 0.00091567717 [0.98042065] [0.17068762]\n",
      "800 0.0006526153 [0.9834706] [0.15967631]\n",
      "850 0.0004651337 [0.9860454] [0.15038033]\n",
      "900 0.000331509 [0.98821914] [0.14253242]\n",
      "950 0.00023627195 [0.99005437] [0.13590702]\n",
      "1000 0.00016839619 [0.99160355] [0.13031363]\n",
      "1050 0.000120018994 [0.9929115] [0.1255916]\n",
      "1100 8.553972e-05 [0.9940157] [0.12160517]\n",
      "1150 6.0966886e-05 [0.9949479] [0.11823966]\n",
      "1200 4.345082e-05 [0.9957349] [0.11539839]\n",
      "1250 3.0968567e-05 [0.9963993] [0.11299972]\n",
      "1300 2.207165e-05 [0.99696016] [0.11097469]\n",
      "1350 1.5731257e-05 [0.99743366] [0.1092651]\n",
      "1400 1.1211571e-05 [0.9978335] [0.1078218]\n",
      "1450 7.990627e-06 [0.9981709] [0.10660338]\n",
      "1500 5.6954464e-06 [0.9984558] [0.10557478]\n",
      "1550 4.058792e-06 [0.9986963] [0.1047064]\n",
      "1600 2.8930258e-06 [0.99889946] [0.10397334]\n",
      "1650 2.0620944e-06 [0.9990709] [0.10335442]\n",
      "1700 1.4698708e-06 [0.99921554] [0.10283195]\n",
      "1750 1.0476064e-06 [0.9993378] [0.10239084]\n",
      "1800 7.465745e-07 [0.99944085] [0.10201847]\n",
      "1850 5.3221913e-07 [0.99952793] [0.10170409]\n",
      "1900 3.7927126e-07 [0.9996015] [0.10143869]\n",
      "1950 2.7040974e-07 [0.9996635] [0.10121461]\n",
      "2000 1.9265103e-07 [0.99971586] [0.10102544]\n"
     ]
    }
   ],
   "source": [
    "#placeholder\n",
    "X = tf.placeholder(tf.float32, shape = [None])\n",
    "Y = tf.placeholder(tf.float32, shape = [None])\n",
    "\n",
    "#tf.randon_normal(shape), [1] => rank1, D0 = 1\n",
    "W = tf.Variable(tf.random_normal([1]), name = 'weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name = 'bias')\n",
    "\n",
    "#Hypothesis XW + b\n",
    "hypothesis = X * W + b\n",
    "\n",
    "#cost(loss) function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y)) \n",
    "\n",
    "\n",
    "##cost의 Minimize!!! (GradientDescent)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.01)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "#위에서 만들어진 graph의 실행!\n",
    "sess = tf.Session()\n",
    "#글로벌 변수 초기화\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "\n",
    "for step in range(2001):\n",
    "    #sess.run(train, feed_dict = {X: [1,2,3], Y: [1,2,3]})\n",
    "    cost_val, W_val, b_val, _ = \\\n",
    "        sess.run([cost, W, b, train], feed_dict = {X: [1,2,3,4,5], Y: [1.1,2.1,3.1,4.1,5.1]})\n",
    "    if step%50 == 0:\n",
    "        #print(step,sess.run(cost),sess.run(W),sess.run(b))\n",
    "        print(step, cost_val, W_val, b_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10.098185 15.096764]\n"
     ]
    }
   ],
   "source": [
    "# Testing the model!!! 테스트 할때에는 hypothesis에 X값 대입해서 결과값을 얻음.\n",
    "print(sess.run(hypothesis, feed_dict = {X : [10,15]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.89884436 [1.1084374] [-0.9877841]\n",
      "2000 2.5879177e-07 [1.0003291] [0.09881176]\n"
     ]
    }
   ],
   "source": [
    "#placeholder\n",
    "X = tf.placeholder(tf.float32, shape = [None])\n",
    "Y = tf.placeholder(tf.float32, shape = [None])\n",
    "\n",
    "#tf.randon_normal(shape), [1] => rank1, D0 = 1\n",
    "W = tf.Variable(tf.random_normal([1]), name = 'weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name = 'bias')\n",
    "\n",
    "#Hypothesis XW + b\n",
    "hypothesis = X * W + b\n",
    "\n",
    "#cost(loss) function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y)) \n",
    "\n",
    "\n",
    "##cost의 Minimize!!! (GradientDescent)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.01)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "#위에서 만들어진 graph의 실행!\n",
    "sess = tf.Session()\n",
    "#글로벌 변수 초기화\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "\n",
    "for step in range(2001):\n",
    "    #sess.run(train, feed_dict = {X: [1,2,3], Y: [1,2,3]})\n",
    "    cost_val, W_val, b_val, _ = \\\n",
    "        sess.run([cost, W, b, train], feed_dict = {X: [1,2,3,4,5], Y: [1.1,2.1,3.1,4.1,5.1]})\n",
    "    if step%2000 == 0:\n",
    "        #print(step,sess.run(cost),sess.run(W),sess.run(b))\n",
    "        print(step, cost_val, W_val, b_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7745037e-06\n"
     ]
    }
   ],
   "source": [
    "#testing (検定)\n",
    "x_test = [6,7,8,9]\n",
    "y_test = [6.1,7.1,8.1,9.1]\n",
    "print(sess.run(cost, feed_dict = {X: x_test, Y: y_test}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
